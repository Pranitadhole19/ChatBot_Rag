{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "411a6690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.3.0)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.10.0-cp310-cp310-win_amd64.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: transformers in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.44.2)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: pypdf in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.3.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (3.10.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (0.3.2)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (0.3.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (0.1.125)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (1.24.3)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (8.2.3)\n",
      "Collecting numpy<2,>=1 (from langchain)\n",
      "  Downloading numpy-1.26.4-cp310-cp310-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 61.0/61.0 kB 1.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from faiss-cpu) (24.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.25.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (2.4.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (1.4.1.post1)\n",
      "Requirement already satisfied: scipy in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (1.13.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (10.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (1.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.5.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\pranita\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
      "Downloading faiss_cpu-1.10.0-cp310-cp310-win_amd64.whl (13.7 MB)\n",
      "   ---------------------------------------- 13.7/13.7 MB 3.7 MB/s eta 0:00:00\n",
      "Downloading sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
      "   ---------------------------------------- 345.7/345.7 kB 2.7 MB/s eta 0:00:00\n",
      "Downloading numpy-1.26.4-cp310-cp310-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 15.8/15.8 MB 3.7 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy, faiss-cpu, sentence-transformers\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.3\n",
      "    Uninstalling numpy-1.24.3:\n",
      "      Successfully uninstalled numpy-1.24.3\n",
      "Successfully installed faiss-cpu-1.10.0 numpy-1.26.4 sentence-transformers-4.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\Pranita\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#!pip install langchain faiss-cpu transformers sentence-transformers pypdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac8fc7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "from transformers import AutoTokenizer\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e71723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set local cache folder for HuggingFace model\n",
    "CACHE_DIR = os.path.normpath(os.path.join(os.getcwd(), \"models\"))\n",
    "\n",
    "class Encoder:\n",
    "    def __init__(self, model_name: str = \"sentence-transformers/all-MiniLM-L12-v2\", device=\"cpu\"):\n",
    "        self.embedding_function = HuggingFaceEmbeddings(\n",
    "            model_name=model_name,\n",
    "            cache_folder=CACHE_DIR,\n",
    "            model_kwargs={\"device\": device},\n",
    "        )\n",
    "\n",
    "class FaissDb:\n",
    "    def __init__(self, docs, embedding_function):\n",
    "        self.db = FAISS.from_documents(\n",
    "            docs, embedding_function, distance_strategy=DistanceStrategy.COSINE\n",
    "        )\n",
    "\n",
    "    def similarity_search(self, question: str, k: int = 3):\n",
    "        return self.db.similarity_search(question, k=k)\n",
    "\n",
    "def load_and_split_pdfs(file_paths: list, chunk_size: int = 512):\n",
    "    loaders = [PyPDFLoader(file_path) for file_path in file_paths]\n",
    "    pages = []\n",
    "    for loader in loaders:\n",
    "        pages.extend(loader.load())\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "        tokenizer=AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L12-v2\"),\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=64,\n",
    "        strip_whitespace=True,\n",
    "    )\n",
    "    docs = text_splitter.split_documents(pages)\n",
    "    return docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6981ce89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09a288af81594a508c6aa6b1ce45bd1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value={}, accept='C:\\\\Users\\\\Pranita\\\\OneDrive\\\\Desktop\\\\Pranita\\\\Pranita-cv\\\\Pranita_Dhole_CV_Recr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "upload = widgets.FileUpload(accept=r\"C:\\Users\\Pranita\\OneDrive\\Desktop\\Data Analysis\\SQL\\Theory.pdf\", multiple=False)\n",
    "display(upload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2843af88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 68 document chunks.\n",
      "PDF loaded and indexed with 68 chunks.\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "\n",
    "# Save the uploaded PDF\n",
    "file_path = r\"C:\\Users\\Pranita\\OneDrive\\Desktop\\Data Analysis\\SQL\\Theory.pdf\"\n",
    "for filename, fileinfo in upload.value.items():\n",
    "    file_path = filename\n",
    "    with open(file_path, 'wb') as f:\n",
    "        f.write(fileinfo['content'])\n",
    "\n",
    "# Load and split\n",
    "docs = load_and_split_pdfs([file_path])\n",
    "\n",
    "# Check if any text was extracted\n",
    "if not docs:\n",
    "    raise ValueError(\"No text could be extracted from the uploaded PDF. Please try with a different file.\")\n",
    "\n",
    "print(f\"Loaded {len(docs)} document chunks.\")\n",
    "\n",
    "encoder = Encoder()\n",
    "\n",
    "# Try generating embeddings\n",
    "texts = [doc.page_content for doc in docs]\n",
    "embeddings = encoder.embedding_function.embed_documents(texts)\n",
    "\n",
    "# Check if embeddings were created\n",
    "if not embeddings:\n",
    "    raise ValueError(\"Embeddings generation failed. Please check your embedding function or input texts.\")\n",
    "\n",
    "# Proceed only if everything is valid\n",
    "faiss_db = FaissDb(docs, encoder.embedding_function)\n",
    "\n",
    "print(f\"PDF loaded and indexed with {len(docs)} chunks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03d33ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question (type 'exit' to stop): what is this file about?\n",
      "\n",
      "🔍 Top Relevant Answers:\n",
      "\n",
      "1. Created by: Vinay Kumar Panika\n",
      "Key Points:\n",
      "Used to process row-by-row results.\n",
      "Slower than set-based operations.\n",
      "Helps in complex data manipulation.\n",
      "Not recommended for large datasets.Example:\n",
      "\n",
      "2. DELETE TRUNCATE\n",
      "Removes specific rows based on a\n",
      "condition using the WHERE clause.Removes all rows from the table without\n",
      "any condition.\n",
      "Can be rolled back using ROLLBACK if\n",
      "inside a transaction.Cannot be rolled back once executed.\n",
      "Slower because it logs each row deletion.Faster because it does not log individual\n",
      "row deletions.\n",
      "Maintains table structure and identity\n",
      "column values.Resets identity column values to the initial\n",
      "seed.\n",
      "Index Fragmentation occurs when the logical order of index pages i\n",
      "\n",
      "3. Created by: Vinay Kumar Panika2. RANK()\n",
      "Assigns a rank to each row with the same values having the same rank, but skips ranks for\n",
      "duplicate values.\n",
      "Syntax:\n",
      "3. DENSE_RANK()\n",
      "Similar to RANK(), but does not skip ranks for duplicate values.\n",
      "Syntax:\n",
      "4. NTILE(n)\n",
      "Divides the result set into n equal parts and assigns a group number to each row.\n",
      "Syntax:\n",
      "5. SUM()\n",
      "Calculates the cumulative total of a column within a partition.\n",
      "Syntax:\n",
      "6. AVG()\n",
      "Calculates the average value of a column within a partition.\n",
      "Sy\n",
      "\n",
      "\n",
      "Ask a question (type 'exit' to stop): exit\n",
      "Chat ended.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    query = input(\"\\nAsk a question (type 'exit' to stop): \")\n",
    "    if query.lower() == 'exit':\n",
    "        print(\"Chat ended.\")\n",
    "        break\n",
    "\n",
    "    results = faiss_db.similarity_search(query)\n",
    "    print(\"\\n🔍 Top Relevant Answers:\\n\")\n",
    "    for i, doc in enumerate(results, 1):\n",
    "        print(f\"{i}. {doc.page_content.strip()[:500]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c6c7e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
